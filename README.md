# IMDB-nlp-analysis
Dataset: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews

# 项目总结

## 数据清理
在项目的初始阶段，我对数据进行了预处理，包括：
- **删除HTML标签**、特殊字符，并统一转为小写。
- 进行了**停用词移除**和**词形还原**以标准化文本。

此步骤确保了文本数据的统一性，减少了噪声。

---

## 模型构建与微调
### 模型架构
- 基于 **DistilBERT** 的预训练模型构建了一个分类器。
- 分类器包含 **全连接层** 和 **Dropout层**，以提升泛化能力，减少过拟合风险。

### 训练配置
1. **优化器**：选择了 **AdamW** 以适配 Transformer 架构，结合交叉熵损失函数。
2. **学习率调度**：使用 **StepLR 调度器** 动态调整学习率，在训练后期降低学习率促进收敛。
3. **超参数选择**：
   - 学习率：初始为 `5e-5`，最终使用 `2e-5`。
   - Dropout 比例：对比了 `0.3~0.5`，最终选择 `0.4`。

---

## 模型训练
由于 GPU 内存的限制，采取了以下优化措施：
- **降低 Batch Size**：从 `16` 减少到 `8`，确保训练稳定性。
- **选择轻量化模型**：替换为 **DistilBERT**，以减少显存占用。
- **梯度累计下降**：通过多步梯度累积模拟较大 Batch Size 的效果，改善模型性能。

最终训练在小规模数据集上表现稳定，避免了显存溢出问题。

---

## 评估指标
通过分类报告、混淆矩阵和准确率等指标评估模型性能：
- **验证集**：准确率达到 **60%**。
- **测试集**：准确率达到 **53.74%**。
- **误差分析**：发现模型对负面情感的召回率较低。

---

## 参数设置的选择与实验结果
1. **Batch Size**：调整至 `8` 后，模型训练稳定且不会导致显存溢出。
2. **学习率**：从 `5e-5` 调低到 `2e-5` 后，收敛速度更快且验证集表现更优。
3. **Dropout 比例**：最终选择 `0.4`，平衡了训练集和验证集的性能。

---

## 基线模型对比
使用 Logistic Regression 结合 TF-IDF 向量化（unigram 与 bigram）的结果作为 Baseline：
- **准确率**：Logistic Regression 在测试集上的准确率为 **70%**，略高于 DistilBERT。
- **特征重要性**：通过 TF-IDF 的权重分析，识别了对情感分类影响较大的词语。

与 Baseline 相比，DistilBERT 在小规模训练集上表现欠佳，但具备更大的优化潜力。

---

## 遇到的挑战及解决方案
1. **GPU 内存不足**：
   - 使用轻量化模型（DistilBERT）。
   - 降低 Batch Size，并使用梯度累计下降。
2. **过拟合**：
   - 增加 Dropout 层以缓解小样本训练中的过拟合。
3. **模型收敛慢**：
   - 使用 StepLR 调度器动态调整学习率，平衡收敛速度与稳定性。
